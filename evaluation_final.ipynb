{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q"
      ],
      "metadata": {
        "id": "oHD0XGDFo3RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown -q"
      ],
      "metadata": {
        "id": "vGMqy1C7Ti-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# должно сработать, потому что я открывала доступ,\n",
        "# но если не работает, то по этой ссылке можно так же попасть в папку с моделями\n",
        "!gdown --folder \"https://drive.google.com/drive/u/0/folders/1QgbnP3IJpMqdGZ-hoJUMtmXM2LAKJypW\""
      ],
      "metadata": {
        "id": "kp40C0V6VeXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    pipeline\n",
        ")\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pickle"
      ],
      "metadata": {
        "id": "Vt0nzSO0qKtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Получение результатов работы модели сущностей на тестовых данных"
      ],
      "metadata": {
        "id": "BS8lMsDro0ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_test_data = \"dev_reviews.txt\"\n",
        "path_to_save_preds = \"dev_pred_aspects.txt\"\n",
        "path_to_save_preds_cats = \"dev_pred_cats.txt\""
      ],
      "metadata": {
        "id": "L7iUHKmjR2wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {\n",
        "    'B-Food': 0, 'B-Interior': 1, 'B-Price': 2, 'B-Service': 3,\n",
        "    'B-Whole': 4, 'I-Food': 5, 'I-Interior': 6, 'I-Price': 7,\n",
        "    'I-Service': 8, 'I-Whole': 9, 'O': 10}\n",
        "\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "\n",
        "def get_entities(text_id, text):\n",
        "    result = classifier(text)\n",
        "    to_return = []\n",
        "    words = []\n",
        "    entities = []\n",
        "    prev_entity = ''\n",
        "    positions = []\n",
        "\n",
        "    for i, token in enumerate(result):\n",
        "        entity_id = int(token['entity'].split('_')[-1])\n",
        "        entity = id2label[entity_id]\n",
        "        start_pos = token['start']\n",
        "        end_pos = token['end']\n",
        "\n",
        "        if token['word'].startswith('##'):\n",
        "            words[-1] += token['word'][2:]\n",
        "            positions[-1][1] = end_pos\n",
        "\n",
        "        elif entity.startswith('I') and entities:\n",
        "            words[-1] += f' {token[\"word\"]}'\n",
        "            positions[-1][1] = end_pos\n",
        "\n",
        "        else:\n",
        "            words.append(token['word'])\n",
        "            entities.append(entity)\n",
        "            positions.append([start_pos, end_pos])\n",
        "\n",
        "        prev_entity = entity\n",
        "\n",
        "    for word, entity, position in zip(words, entities, positions):\n",
        "        if entity != 'O':\n",
        "            to_return.append([str(text_id), entity[2:], word, str(position[0]), str(position[1]), 'neutral'])\n",
        "\n",
        "    return to_return"
      ],
      "metadata": {
        "id": "KSmHsUiao8MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"ner\", model=\"models/bert_wo_crf_deepvk_uncased_1e02\")"
      ],
      "metadata": {
        "id": "Svq5ksSlovJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Чтение тестовых данных и получение предсказаний"
      ],
      "metadata": {
        "id": "ZlbS-jRVgmgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(path_to_test_data, sep='\\t', names=['idx', 'text'])"
      ],
      "metadata": {
        "id": "5qRrHLvrpuXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "all_results = []\n",
        "for i, row in tqdm(data.iterrows()):\n",
        "    all_results.extend(get_entities(row['idx'], row['text']))"
      ],
      "metadata": {
        "id": "5nRwM02KqdAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_save = '\\n'.join(['\\t'.join(result) for result in all_results])"
      ],
      "metadata": {
        "id": "n0YwXm5rrGp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_to_save_preds, 'w') as f:\n",
        "    f.write(to_save)"
      ],
      "metadata": {
        "id": "R4B3MVrrsVNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Предсказание тональности аспектов"
      ],
      "metadata": {
        "id": "EJCO8ITTg6bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для извлечения контекста вокруг аспекта с учетом целых слов\n",
        "def extract_context_with_category(text, start, end, category, window=50):\n",
        "    # Находим начало контекста и пробел назад от начальной позиции аспекта\n",
        "    start_idx = max(0, start - window)\n",
        "    while start_idx > 0 and text[start_idx] != ' ':\n",
        "        start_idx -= 1\n",
        "\n",
        "    # Находим конец контекста и пробел вперед от конечной позиции аспекта\n",
        "    end_idx = min(len(text), end + window)\n",
        "    while end_idx < len(text) and text[end_idx] != ' ':\n",
        "        end_idx += 1\n",
        "\n",
        "    context = text[start_idx:end_idx].strip()\n",
        "    return category + \" \" + context  # Добавление категории аспекта"
      ],
      "metadata": {
        "id": "bvZyNrWC3iDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {'negative': 0, 'neutral': 1, 'positive': 2, 'both': 3}\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_path = \"models/bert_model.pth\"\n",
        "model_name = 'DeepPavlov/rubert-base-cased'\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(label_dict))\n",
        "\n",
        "# Загрузка сохраненных весов\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "blXF-Auc6rFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_aspects = pd.read_csv(path_to_save_preds, sep='\\t', names=['review_id', 'aspect_category', 'aspect_text', 'start_pos', 'end_pos', 'sentiment'])\n",
        "dev_reviews = pd.read_csv(path_to_test_data, sep='\\t', names=['review_id', 'review_text'])\n",
        "\n",
        "# Объединение данных\n",
        "merged_data = pd.merge(dev_aspects, dev_reviews, on='review_id')\n",
        "\n",
        "# Добавление контекста к данным\n",
        "merged_data['context'] = merged_data.apply(lambda row: extract_context_with_category(row['review_text'], row['start_pos'], row['end_pos'], row['aspect_category']), axis=1)"
      ],
      "metadata": {
        "id": "vgriZApuirDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(model_name, model_max_length=512)\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    encoded_input = tokenizer.encode_plus(\n",
        "        text,\n",
        "        max_length=64,\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "    )\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    # Возвращаем тональность аспекта\n",
        "    return list(label_dict.keys())[list(label_dict.values()).index(prediction)]\n",
        "\n",
        "# Применение модели к каждому контексту и обновление значения тональности\n",
        "dev_aspects['sentiment'] = merged_data['context'].apply(predict_sentiment)\n",
        "\n",
        "dev_aspects.to_csv(path_to_save_preds, sep='\\t', index=False, header=False)"
      ],
      "metadata": {
        "id": "hoWdeK8IiYG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Предсказание тональности отзывов по категориям"
      ],
      "metadata": {
        "id": "f26oYHo8HuJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузка сохраненной модели\n",
        "with open('models/lr_model.pkl', 'rb') as file:\n",
        "    clf = pickle.load(file)"
      ],
      "metadata": {
        "id": "BP8dE_35H0HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_aspects = pd.read_csv(\n",
        "    path_to_save_preds,\n",
        "    delimiter='\\t',\n",
        "    names=['text_id', 'category', 'mention', 'start', 'end', 'sentiment'])"
      ],
      "metadata": {
        "id": "gKre7Ft-H6rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = ['Food', 'Interior', 'Price', 'Whole', 'Service']"
      ],
      "metadata": {
        "id": "NTOcJJ0bIRpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# функция, подсчитывающая количество positives, negatives, neutrals и both для каждой категории\n",
        "def count(aspects):\n",
        "    text_ids = aspects['text_id'].unique()\n",
        "\n",
        "    new_entry = {}\n",
        "    entries = []\n",
        "    for text_id in text_ids:\n",
        "        for c in CATEGORIES:\n",
        "            positive = 0\n",
        "            negative = 0\n",
        "            neutral = 0\n",
        "            both = 0\n",
        "\n",
        "            if not aspects[(aspects['text_id']==text_id) & (aspects['category']==c)]['category'].empty:\n",
        "                for i in range(len(aspects[(aspects['text_id']==text_id) & (aspects['category']==c)]['sentiment'])):\n",
        "                    if aspects[(aspects['text_id']==text_id) & (aspects['category']==c)]['sentiment'].iloc[i] == 'positive':\n",
        "                        positive += 1\n",
        "                    elif aspects[(aspects['text_id']==text_id) & (aspects['category']==c)]['sentiment'].iloc[i] == 'negative':\n",
        "                        negative += 1\n",
        "                    elif aspects[(aspects['text_id']==text_id) & (aspects['category']==c)]['sentiment'].iloc[i] == 'neutral':\n",
        "                        neutral += 1\n",
        "                    elif aspects[(aspects['text_id']==text_id) & (aspects['category']==c)]['sentiment'].iloc[i] == 'both':\n",
        "                        both += 1\n",
        "\n",
        "            new_entry = {'text_id': text_id, 'category': c, 'positive': positive, 'negative': negative, 'neutral': neutral, 'both': both}\n",
        "            entries.append(new_entry)\n",
        "    df = pd.DataFrame.from_records(entries)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-i2xJvSWITQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = count(test_aspects)"
      ],
      "metadata": {
        "id": "Q4_4hUVSIk1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(test[list(test.keys()[2::])])"
      ],
      "metadata": {
        "id": "T47LYbxhIokc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузка классов, использывавшихся при обучении, для энкодера, чтобы дальше вернуться обратно к positive, negative, neutral и both\n",
        "LE = preprocessing.LabelEncoder()\n",
        "LE.classes_ = np.load('models/classes.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "2VTvm-ANIswG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test = test\n",
        "y = LE.inverse_transform(y_pred)\n",
        "new_test['sentiment'] = y\n",
        "new_test.drop(['positive', 'negative', 'neutral', 'both'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "mAwqEvH0I6n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test.to_csv(path_to_save_preds_cats, sep='\\t', header=False, index=False)"
      ],
      "metadata": {
        "id": "rxJnGLgpI_XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценивание"
      ],
      "metadata": {
        "id": "iGho1LAKoyrR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voV6RarIoccZ"
      },
      "outputs": [],
      "source": [
        "gold_test_path = \"dev_aspects.txt\"\n",
        "pred_test_path = \"dev_pred_aspects.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "gold_aspect_cats = {}\n",
        "with open(gold_test_path) as fg:\n",
        "    for line in fg:\n",
        "        line = line.rstrip('\\r\\n').split('\\t')\n",
        "        if line[0] not in gold_aspect_cats:\n",
        "            gold_aspect_cats[line[0]] = {\"starts\":[], \"ends\":[], \"cats\":[], \"sents\":[]}\n",
        "        gold_aspect_cats[line[0]][\"starts\"].append(int(line[3]))\n",
        "        gold_aspect_cats[line[0]][\"ends\"].append(int(line[4]))\n",
        "        gold_aspect_cats[line[0]][\"cats\"].append(line[1])\n",
        "        gold_aspect_cats[line[0]][\"sents\"].append(line[5])"
      ],
      "metadata": {
        "id": "nOFaAuVHokoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_match, partial_match, full_cat_match, partial_cat_match = 0, 0, 0, 0\n",
        "total = 0\n",
        "fully_matched_pairs = []\n",
        "partially_matched_pairs = []\n",
        "with open(pred_test_path) as fp:\n",
        "    for line in fp:\n",
        "        total += 1\n",
        "        line = line.rstrip('\\r\\n').split('\\t')\n",
        "        start, end = int(line[3]), int(line[4])\n",
        "        category = line[1]\n",
        "        doc_gold_aspect_cats = gold_aspect_cats[line[0]]\n",
        "        if start in doc_gold_aspect_cats[\"starts\"]:\n",
        "            i = doc_gold_aspect_cats[\"starts\"].index(start)\n",
        "            if doc_gold_aspect_cats[\"ends\"][i] == end:\n",
        "                full_match += 1\n",
        "                if doc_gold_aspect_cats[\"cats\"][i] == category:\n",
        "                    full_cat_match += 1\n",
        "                else:\n",
        "                    partial_cat_match += 1\n",
        "                fully_matched_pairs.append(\n",
        "                    (\n",
        "                        [\n",
        "                            doc_gold_aspect_cats[\"starts\"][i],\n",
        "                            doc_gold_aspect_cats[\"ends\"][i],\n",
        "                            doc_gold_aspect_cats[\"cats\"][i],\n",
        "                            doc_gold_aspect_cats[\"sents\"][i]\n",
        "                        ],\n",
        "                        line\n",
        "                    )\n",
        "                )\n",
        "                continue\n",
        "        for s_pos in doc_gold_aspect_cats[\"starts\"]:\n",
        "            if start <= s_pos:\n",
        "                i = doc_gold_aspect_cats[\"starts\"].index(s_pos)\n",
        "                if doc_gold_aspect_cats[\"ends\"][i] == end:\n",
        "                    partial_match += 1\n",
        "                    partially_matched_pairs.append(\n",
        "                        (\n",
        "                            [\n",
        "                                doc_gold_aspect_cats[\"starts\"][i],\n",
        "                                doc_gold_aspect_cats[\"ends\"][i],\n",
        "                                doc_gold_aspect_cats[\"cats\"][i],\n",
        "                                doc_gold_aspect_cats[\"sents\"][i]\n",
        "                            ],\n",
        "                            line\n",
        "                        )\n",
        "                    )\n",
        "                    if doc_gold_aspect_cats[\"cats\"][i] == category:\n",
        "                        partial_cat_match += 1\n",
        "                    continue\n",
        "                matched = False\n",
        "                for e_pos in doc_gold_aspect_cats[\"ends\"][i:]:\n",
        "                    if s_pos <= end <= e_pos:\n",
        "                        partial_match += 1\n",
        "                        partially_matched_pairs.append(\n",
        "                            (\n",
        "                                [\n",
        "                                    doc_gold_aspect_cats[\"starts\"][i],\n",
        "                                    doc_gold_aspect_cats[\"ends\"][i],\n",
        "                                    doc_gold_aspect_cats[\"cats\"][i],\n",
        "                                    doc_gold_aspect_cats[\"sents\"][i]\n",
        "                                ],\n",
        "                                line\n",
        "                            )\n",
        "                        )\n",
        "                        if doc_gold_aspect_cats[\"cats\"][i] == category:\n",
        "                            partial_cat_match += 1\n",
        "                        matched = True\n",
        "                        break\n",
        "                if matched:\n",
        "                    break\n",
        "            if start > s_pos:\n",
        "                i = doc_gold_aspect_cats[\"starts\"].index(s_pos)\n",
        "                if start < doc_gold_aspect_cats[\"ends\"][i] <= end:\n",
        "                    partial_match += 1\n",
        "                    partially_matched_pairs.append(\n",
        "                        (\n",
        "                            [\n",
        "                                doc_gold_aspect_cats[\"starts\"][i],\n",
        "                                doc_gold_aspect_cats[\"ends\"][i],\n",
        "                                doc_gold_aspect_cats[\"cats\"][i],\n",
        "                                doc_gold_aspect_cats[\"sents\"][i]\n",
        "                            ],\n",
        "                            line\n",
        "                        )\n",
        "                    )\n",
        "                    if doc_gold_aspect_cats[\"cats\"][i] == category:\n",
        "                        partial_cat_match += 1\n",
        "                    break"
      ],
      "metadata": {
        "id": "n-vQASV9oqyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метрики по сущностям"
      ],
      "metadata": {
        "id": "TXmneq4Z8P_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gold_size = sum([len(gold_aspect_cats[x][\"cats\"]) for x in gold_aspect_cats])\n",
        "print(f\"\"\"\n",
        "Full match precision: {full_match / total}\n",
        "Full match recall: {full_match / gold_size}\n",
        "Partial match ratio in pred: {(full_match + partial_match)  / total}\n",
        "Full category accuracy: {full_cat_match / total}\n",
        "Partial category accuracy: {(full_cat_match + partial_cat_match) / total}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "fK-QIsuwu_uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метрики по тональностям аспектов"
      ],
      "metadata": {
        "id": "pVOED5Hi8EQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_accuracy(matches):\n",
        "    matched_sentiment = 0.\n",
        "    for pair in matches:\n",
        "        *_, gold_s = pair[0]\n",
        "        *_, pred_s = pair[1]\n",
        "        if gold_s == pred_s:\n",
        "            matched_sentiment += 1\n",
        "    print(f\"Mention sentiment accuracy: {matched_sentiment / len(matches)}\")"
      ],
      "metadata": {
        "id": "eVRs3SD06K1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_accuracy(fully_matched_pairs)"
      ],
      "metadata": {
        "id": "JXsVe64J8EzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_accuracy(partially_matched_pairs)"
      ],
      "metadata": {
        "id": "wLvPrX1F8HQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Метрика по тональностям отзывов"
      ],
      "metadata": {
        "id": "bfmtuoBnJEGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gold_test_cats_path = \"dev_cats.txt\"\n",
        "pred_test_cats_path = \"dev_pred_cats.txt\""
      ],
      "metadata": {
        "id": "yZwRX4SMJH_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(gold_test_cats_path) as gc, open(pred_test_cats_path) as pc:\n",
        "    gold_labels = set(gc.readlines())\n",
        "    pred_labels = set(pc.readlines())\n",
        "    print(\n",
        "        \"Overall sentiment accuracy:\",\n",
        "        len(gold_labels & pred_labels) / len(gold_labels)\n",
        "    )"
      ],
      "metadata": {
        "id": "OZxEJCjIJOCK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}